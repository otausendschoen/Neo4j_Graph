{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d80d46ad",
   "metadata": {},
   "source": [
    "# Part C. Graph Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709dd7c3",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f86708",
   "metadata": {},
   "source": [
    "For the last task in this lab assignment we use one of the presented algorithms to inspect the data in a different way in a strive to learn new aspects of it. The algorithm we uplan to use in this section is a Centrality Algorithm, that will measure our most influential authors. For this, we will use PageRank."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb224d61",
   "metadata": {},
   "source": [
    "PageRank is a website ranking algorithm that asks: **which pages are the most “important”?**\n",
    "\n",
    "Pages that have many incoming links — especially from other well‑linked pages — are more central to the Website network, thus more influential. That centrality becomes the PageRank score. \n",
    "\n",
    "The idea in this section is to adapt the same idea to our citation network to find influential authors instead of pages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5725af4e",
   "metadata": {},
   "source": [
    "These are the numbers that our dataset has, which allow us to work nicely with this algorithm:\n",
    "\n",
    "- Total Authors =3866419\n",
    "\n",
    "- Total Articles = 3837322\n",
    "\n",
    "- Total Author → Article edges = 13132253\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b29025",
   "metadata": {},
   "source": [
    "After an initial inspection of the data we stumble upon what could become a problem. We find that the vast majority of articles have a signle author, but the articles with the highest amount of authors have very disproportionate numbers, which could damage our results. Below are the queries used for this small inspection: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9be95f",
   "metadata": {},
   "source": [
    "### Query to randomise a sample of 50 journals and collect their respective number of authors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac5b5fd",
   "metadata": {},
   "source": [
    "```bash\n",
    "MATCH (p:article)-[:authored_by]->(a:author)\n",
    "WITH p, count(a) AS authorCount, rand() AS r\n",
    "ORDER BY r\n",
    "LIMIT 50\n",
    "RETURN\n",
    "  p.key, p.title, authorCount;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9fb8a3",
   "metadata": {},
   "source": [
    "### Query to extract the number of authors the top 70 papers with the highest amounts of authors have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3b41b6",
   "metadata": {},
   "source": [
    "```bash\n",
    "MATCH (p:article)-[:authored_by]->(a:author)\n",
    "WITH p, count(a) AS authorCount\n",
    "RETURN\n",
    "  p.key           AS articleKey,\n",
    "  p.title         AS articleTitle,\n",
    "  authorCount     AS numAuthors\n",
    "ORDER BY numAuthors DESC\n",
    "LIMIT 70;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc45f4e1",
   "metadata": {},
   "source": [
    "### Query to count how many articles have over 5 authors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deef4c7e",
   "metadata": {},
   "source": [
    "```bash\n",
    "MATCH \n",
    "  (a:author)<-[:authored_by]-(p:article)\n",
    "WITH \n",
    "  p, \n",
    "  count(DISTINCT a) AS numAuthors\n",
    "WHERE \n",
    "  numAuthors > 5\n",
    "RETURN \n",
    "  count(DISTINCT p) AS journalsWithOver5Authors;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f108ca8",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a552f2",
   "metadata": {},
   "source": [
    "From this very last query, we can observe that, out of 3837322 articles, we have 491979 with over 5 authors, 39161 with over 10, and only 4540 with 20 authors or more. The top 70 ariticles with hgihest amount of authors all have over 100 authors (some with more than 400), which can be a threat to our algorithm. Let's explore why:\n",
    "\n",
    "A paper with N authors that cites another paper with M authors creates N×M author→author edges. for large N or M, we can easily add tens of thousands of edges, from a single publication. \n",
    "\n",
    "Additionally, all those edges carry equal weight in classic PageRank. An author on a 200‑author paper “votes” just as strongly as a sole author on a 1‑author paper. This inflates the connectivity of authors who simply happened to join large consortia. PageRank rewards nodes with high in‑degree and connections to other high‑rank nodes, hence A few mega‑author papers can  dominate the rank distribution, concealing the truly more influential authors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5879017",
   "metadata": {},
   "source": [
    "To avoid this problems, we slightly switch our strategy. Instead of measuring the most influential authors, we will only measure the most influential papers. This means that our nodes will now be articles, with citations amongst each other. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f92157",
   "metadata": {},
   "source": [
    "## 3. Algorithm and query definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e9ebae",
   "metadata": {},
   "source": [
    "Let's now go over the pipeline:\n",
    "We firstly create a citation graph. We want a directed graph where each node is an article, and there’s an edge\n",
    "A → B whenever any paper  A is cited by any paper B. \n",
    "\n",
    "We then run the PageRank algorithm, and finally inspect the results. Note that we use a damping effect of 0.85, which avoids rank sinks ( strands of uncited papers). This algorithm allows us to not only highlight papers that are not just heavily cited, but whose citers are themselves influential.\n",
    "\n",
    "Due to the lack of citation data we have commented on before, we have automated the creation of some citation relationships. For a total sample of around 150 articles, we have created one or two citations to other articles. this allows us to see a mini version of Page Rank, ramking among that subgraph.\n",
    "\n",
    "\n",
    " Below are the Cypher queries to do so:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db323bd",
   "metadata": {},
   "source": [
    "```bash\n",
    "// 1. Drop any existing projection with that name\n",
    "CALL gds.graph.drop('articleCiteGraph', false)\n",
    "YIELD graphName;\n",
    "\n",
    "// 2. Project a new in‑RAM graph called “articleCiteGraph”\n",
    "//    - Nodes: all nodes with the label :article\n",
    "//    - Rels :HAS_CITATION, directed\n",
    "CALL gds.graph.project(\n",
    "  'articleCiteGraph',           // name of your in‑RAM graph\n",
    "  ['article'],                  // list of node labels to include\n",
    "  {HAS_CITATION: {type: 'HAS_CITATION'}}  // map of rel‑types to include\n",
    ")\n",
    "YIELD graphName, nodeCount, relationshipCount;\n",
    "\n",
    "RETURN graphName, nodeCount, relationshipCount;\n",
    "\n",
    "\n",
    "\n",
    "// part 2. Run PageRank Algorithm\n",
    "CALL gds.pageRank.stream(\n",
    "  'articleCiteGraph',\n",
    "  {\n",
    "    maxIterations: 20,\n",
    "    dampingFactor: 0.85\n",
    "  }\n",
    ")\n",
    "YIELD nodeId, score\n",
    "RETURN\n",
    "  gds.util.asNode(nodeId).title  AS paperTitle,\n",
    "  gds.util.asNode(nodeId).key    AS paperKey,\n",
    "  round(score,4)                 AS pageRankScore\n",
    "ORDER BY pageRankScore DESC\n",
    "LIMIT 10;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dd248a",
   "metadata": {},
   "source": [
    "The previous algorithm is implemented in seconds and yields the following results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255bbee1",
   "metadata": {},
   "source": [
    "## 4. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a67163f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paperTitle</th>\n",
       "      <th>paperKey</th>\n",
       "      <th>pageRankScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Entropy-accelerated exact clustering of protei...</td>\n",
       "      <td>journals/bioinformatics/BerengerZSZ11</td>\n",
       "      <td>5.3230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MUMBO: MUlti-task Max-value Bayesian Optimizat...</td>\n",
       "      <td>journals/corr/abs-2006-12093</td>\n",
       "      <td>4.1820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Study of a Numerical Approach for a Transient ...</td>\n",
       "      <td>journals/na/ChakibGN03</td>\n",
       "      <td>4.1653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fault-Tolerant Design Techniques for Semicondu...</td>\n",
       "      <td>journals/ibmrd/Aichelmann84</td>\n",
       "      <td>2.9362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The rise of accounting information systems.</td>\n",
       "      <td>journals/ijais/GrabskiL23</td>\n",
       "      <td>1.4433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DropFilterR: A Novel Regularization Method for...</td>\n",
       "      <td>journals/npl/PanNLSD20</td>\n",
       "      <td>1.3991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Multipath Aided Rapid Acquisition: Optimal Sea...</td>\n",
       "      <td>journals/tit/SuwansantisukW07</td>\n",
       "      <td>1.3347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bordertown and the Globalisation of Justice: U...</td>\n",
       "      <td>journals/jilt/McInnes98</td>\n",
       "      <td>1.2845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A new combination of evidence based on comprom...</td>\n",
       "      <td>journals/fss/Yamada08</td>\n",
       "      <td>1.2808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Load dispersion-aware VM placement in favor of...</td>\n",
       "      <td>journals/tjs/NadjarAD17</td>\n",
       "      <td>1.2761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          paperTitle  \\\n",
       "0  Entropy-accelerated exact clustering of protei...   \n",
       "1  MUMBO: MUlti-task Max-value Bayesian Optimizat...   \n",
       "2  Study of a Numerical Approach for a Transient ...   \n",
       "3  Fault-Tolerant Design Techniques for Semicondu...   \n",
       "4        The rise of accounting information systems.   \n",
       "5  DropFilterR: A Novel Regularization Method for...   \n",
       "6  Multipath Aided Rapid Acquisition: Optimal Sea...   \n",
       "7  Bordertown and the Globalisation of Justice: U...   \n",
       "8  A new combination of evidence based on comprom...   \n",
       "9  Load dispersion-aware VM placement in favor of...   \n",
       "\n",
       "                                paperKey  pageRankScore  \n",
       "0  journals/bioinformatics/BerengerZSZ11         5.3230  \n",
       "1           journals/corr/abs-2006-12093         4.1820  \n",
       "2                 journals/na/ChakibGN03         4.1653  \n",
       "3            journals/ibmrd/Aichelmann84         2.9362  \n",
       "4              journals/ijais/GrabskiL23         1.4433  \n",
       "5                 journals/npl/PanNLSD20         1.3991  \n",
       "6          journals/tit/SuwansantisukW07         1.3347  \n",
       "7                journals/jilt/McInnes98         1.2845  \n",
       "8                  journals/fss/Yamada08         1.2808  \n",
       "9                journals/tjs/NadjarAD17         1.2761  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('PageRank.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b80747",
   "metadata": {},
   "source": [
    "Given that data was created synthetically for the sole purpose of playing with the algorithm, we cannot extract much interpretation of the results obtained. With real life data, we could perhaps check if the results of the alleged most influential papers are really important papers in real life. \n",
    "\n",
    "However, it is clear that the pipeline was executed nicely and we obtained coherent results. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
